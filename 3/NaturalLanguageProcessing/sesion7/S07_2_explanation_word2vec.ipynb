{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvNCXd9Dfqe1"
   },
   "source": [
    "# Word2vec with gensim\n",
    "\n",
    "In this Jupyter notebook you will use the [Gensim] library (https://radimrehurek.com/gensim/index.html) to experiment with Word2VEC.This notebook is focused on the intuition of the concepts and not on the implementation details.This notebook is inspired by this [Guide] (https://radicrehurek.com/gensim/auto_examples/ttorials/run_word2vec.html).\n",
    "\n",
    "## 1. Installation and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zKIqnDXXfpiz"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Sn7Q2jB3frOn"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mapi\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yBaT8djWkaZy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVZm7iTOoawW"
   },
   "source": [
    "## 2. Similarity of words\n",
    "\n",
    "In this section we will see how to achieve the similarity between two words using a Word Embedding already trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kOZfaelLoi4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510956"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"king\", \"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BX-Kk9HZofuF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2294267"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"king\", \"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ypFK-pLrol3N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09978465"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"king\", \"potato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rBWzZySFormq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"king\", \"king\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GijWs_tx83W"
   },
   "source": [
    "Now we will see how to find the words with greater similarity to the set of specified words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ytELAWBLk2-6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('monarch', 0.7042065858840942),\n",
       " ('kings', 0.6780861020088196),\n",
       " ('princess', 0.6731551885604858),\n",
       " ('queens', 0.6679496765136719),\n",
       " ('prince', 0.6435247659683228)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([\"king\", \"queen\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7D4ZS7N3ovxB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('carrots', 0.7536594271659851),\n",
       " ('tomatoes', 0.7129638195037842),\n",
       " ('celery', 0.7025030851364136),\n",
       " ('broccoli', 0.6796351075172424),\n",
       " ('cherry_tomatoes', 0.6629275679588318)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([\"tomato\", \"carrot\"], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZFlxKjOyBpu"
   },
   "source": [
    "But you can even do interesting things such as seeing what word does not correspond to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8CrZdcBpn3pn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'air'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match([\"summer\", \"fall\", \"spring\", \"air\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko09hZ3dqMZ1"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. Use the Word2VEC model to make a ranking of the following 15 words according to its similarity with the words \"man\" and \"Woman\".For each pair, it prints its similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vzZ1eD3PpT-d"
   },
   "outputs": [],
   "source": [
    "words = [\n",
    "\"wife\",\n",
    "\"husband\",\n",
    "\"child\",\n",
    "\"queen\",\n",
    "\"king\",\n",
    "\"man\",\n",
    "\"woman\",\n",
    "\"birth\",\n",
    "\"doctor\",\n",
    "\"nurse\",\n",
    "\"teacher\",\n",
    "\"professor\",\n",
    "\"engineer\",\n",
    "\"scientist\",\n",
    "\"president\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKamywnxqxJJ"
   },
   "source": [
    "** 2. Complete the following analogies on your own (without using the model) **\n",
    "\n",
    "a. king is to throne as judge is to _\n",
    "\n",
    "b. giant is to dwarf as genius is to _\n",
    "\n",
    "c. French is to France as Spaniard is to _\n",
    "\n",
    "d. bad is to good as sad is to _\n",
    "\n",
    "e. nurse is to hospital as teacher is to _\n",
    "\n",
    "f. universe is to planet as house is to _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcNRxHuZrXAM"
   },
   "source": [
    "**3. Ahora completa las analogías usando un modelo word2vec**\n",
    "\n",
    "Aquí hay un ejemplo de cómo hacerlo. Puedes resolver analogías como \"A es a B como C es a _\" haciendo A + C - B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "K4kF08h4qhxM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# man is to woman as king is to ___?\n",
    "model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DiPbbGsori48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('taco', 0.6266060471534729)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# us is to burger as italy is to ___?\n",
    "model.most_similar(positive=[\"Mexico\", \"burger\"], negative=[\"USA\"], topn=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOnghp0wIfCZSJ+lSjdKnPj",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Word2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
