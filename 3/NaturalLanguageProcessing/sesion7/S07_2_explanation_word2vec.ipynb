{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvNCXd9Dfqe1"
      },
      "source": [
        "# Word2vec with gensim\n",
        "\n",
        "In this Jupyter notebook you will use the [Gensim] library (https://radimrehurek.com/gensim/index.html) to experiment with Word2VEC.This notebook is focused on the intuition of the concepts and not on the implementation details.This notebook is inspired by this [Guide] (https://radicrehurek.com/gensim/auto_examples/ttorials/run_word2vec.html).\n",
        "\n",
        "## 1. Installation and loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKIqnDXXfpiz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
            "Downloading gensim-4.3.3-cp311-cp311-macosx_11_0_arm64.whl (24.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-macosx_12_0_arm64.whl (30.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
            "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        }
      ],
      "source": [
        "#!pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sn7Q2jB3frOn"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yBaT8djWkaZy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "model = api.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVZm7iTOoawW"
      },
      "source": [
        "## 2. Similarity of words\n",
        "\n",
        "In this section we will see how to achieve the similarity between two words using a Word Embedding already trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kOZfaelLoi4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6510956"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.similarity(\"king\", \"queen\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BX-Kk9HZofuF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2294267"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.similarity(\"king\", \"man\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ypFK-pLrol3N"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.09978465"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.similarity(\"king\", \"potato\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rBWzZySFormq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.99999994"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.similarity(\"king\", \"king\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GijWs_tx83W"
      },
      "source": [
        "Now we will see how to find the words with greater similarity to the set of specified words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ytELAWBLk2-6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('monarch', 0.7042065858840942),\n",
              " ('kings', 0.6780861020088196),\n",
              " ('princess', 0.6731551885604858),\n",
              " ('queens', 0.6679496765136719),\n",
              " ('prince', 0.6435247659683228)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar([\"king\", \"queen\"], topn=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7D4ZS7N3ovxB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('carrots', 0.7536594271659851),\n",
              " ('tomatoes', 0.7129638195037842),\n",
              " ('celery', 0.7025030851364136),\n",
              " ('broccoli', 0.6796351075172424),\n",
              " ('cherry_tomatoes', 0.6629275679588318)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.most_similar([\"tomato\", \"carrot\"], topn=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZFlxKjOyBpu"
      },
      "source": [
        "But you can even do interesting things such as seeing what word does not correspond to a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8CrZdcBpn3pn"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'air'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.doesnt_match([\"summer\", \"fall\", \"spring\", \"air\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko09hZ3dqMZ1"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1. Use the Word2VEC model to make a ranking of the following 15 words according to its similarity with the words \"man\" and \"Woman\".For each pair, it prints its similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vzZ1eD3PpT-d"
      },
      "outputs": [],
      "source": [
        "words = [\n",
        "\"wife\",\n",
        "\"husband\",\n",
        "\"child\",\n",
        "\"queen\",\n",
        "\"king\",\n",
        "\"man\",\n",
        "\"woman\",\n",
        "\"birth\",\n",
        "\"doctor\",\n",
        "\"nurse\",\n",
        "\"teacher\",\n",
        "\"professor\",\n",
        "\"engineer\",\n",
        "\"scientist\",\n",
        "\"president\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKamywnxqxJJ"
      },
      "source": [
        "** 2. Complete the following analogies on your own (without using the model) **\n",
        "\n",
        "a. king is to throne as judge is to _\n",
        "\n",
        "b. giant is to dwarf as genius is to _\n",
        "\n",
        "c. French is to France as Spaniard is to _\n",
        "\n",
        "d. bad is to good as sad is to _\n",
        "\n",
        "e. nurse is to hospital as teacher is to _\n",
        "\n",
        "f. universe is to planet as house is to _"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcNRxHuZrXAM"
      },
      "source": [
        "**3. Ahora completa las analogías usando un modelo word2vec**\n",
        "\n",
        "Aquí hay un ejemplo de cómo hacerlo. Puedes resolver analogías como \"A es a B como C es a _\" haciendo A + C - B. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "K4kF08h4qhxM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('queen', 0.7118192911148071)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# man is to woman as king is to ___?\n",
        "model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DiPbbGsori48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('taco', 0.6266060471534729)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# us is to burger as italy is to ___?\n",
        "model.most_similar(positive=[\"Mexico\", \"burger\"], negative=[\"USA\"], topn=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOnghp0wIfCZSJ+lSjdKnPj",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Word2vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
