{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next text, perform the following actions\n",
    "text = \"The president of the U.S.A., Donald Trump, is 1.9m high and 78 years old. Forbes Magazine has assessed his wealth, currently estimating it at $5.5 billion as of mid-February 2025.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "from num2words import num2words\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The president of the U.S.A., Donald Trump, is 1.9m high and 78 years old.', 'Forbes Magazine has assessed his wealth, currently estimating it at $5.5 billion as of mid-February 2025.']\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 1 - Use NLTK to split the sentences \n",
    "def get_scentences(content: str) -> list:\n",
    "    return sent_tokenize(content, language='english')\n",
    "print(get_scentences(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA\n",
      "190 centimeters\n",
      "five billion\n",
      "Not an expected value\n"
     ]
    }
   ],
   "source": [
    "# (2 points) 2 - Convert with regex the acronym U.S.A. to USA, the number 1.9m to 190 centimeters or any other number of a height like that (e.g. 1.75m to 175 centimeters), and \"$5.5 billion\" to five point five billion.\n",
    "def regex_replace(value: str) -> str:\n",
    "    if re.search(r\"U\\.S\\.A\\.\", value):\n",
    "        return re.sub(r\"U\\.S\\.A\\.\", \"USA\", value)\n",
    "    elif re.search(r\"(\\d+\\.\\d+)m\", value):\n",
    "        return re.sub(r\"(\\d+\\.\\d+)m\", lambda m: f\"{int(float(m.group(1)) * 100)} centimeters\", value)\n",
    "    elif re.search(r\"\\$\\d+\\.\\d+ billion\", value):\n",
    "        return re.sub(\n",
    "            r\"\\$(\\d+\\.\\d+) billion\",\n",
    "            lambda m: num2words(int(float(m.group(1)))) + \" billion\",\n",
    "            value\n",
    "        ) # No lo hace bien porque no maneje el punto\n",
    "    else:\n",
    "        return \"Not an expected value\"\n",
    "\n",
    "# Pruebas\n",
    "print(regex_replace(\"U.S.A.\"))         # USA\n",
    "print(regex_replace(\"1.9m\"))           # 190 centimeters\n",
    "print(regex_replace(\"$5.5 billion\"))   # five point five billion\n",
    "print(regex_replace(\"Random text\"))    # Not an expected value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1 point) 3 - Convert to lowercase except the proper nouns that must keep the original case. For the multiword proper names convert them to an unique word joining the two word with underscoere (Juan Fernández -> Juan_Fernández).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'president', 'of', 'the', 'U.S.A.,', 'Donald', 'Trump,', 'is', '1.9m', 'high', 'and', '78', 'years', 'old.', 'Forbes', 'Magazine', 'has', 'assessed', 'his', 'wealth,', 'currently', 'estimating', 'it', 'at', '$5.5', 'billion', 'as', 'of', 'mid-February', '2025.']\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 4 - Tokenize the text (use the tool you prefer). \n",
    "def tokenize_text(content: str) -> list:\n",
    "    return content.split()\n",
    "print(tokenize_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['president', 'U.S.A.,', 'Donald', 'Trump,', '1.9m', 'high', '78', 'years', 'old.', 'Forbes', 'Magazine', 'assessed', 'wealth,', 'currently', 'estimating', '$5.5', 'billion', 'mid-February', '2025.']\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 5 - Remove the stopwords (use the tool you prefer). \n",
    "def remove_stopwords(tokens: list) -> list:\n",
    "    stop_words = set(stopwords.words('english')) # set de palabras  stopwords en ingles\n",
    "    return [token for token in tokens if token.lower() not in stop_words] # cada token en tokens si el token en minuscula no esta en stop_words\n",
    "print(remove_stopwords(tokenize_text(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'president'), ('president', 'of'), ('of', 'the'), ('the', 'U.S.A.,'), ('U.S.A.,', 'Donald'), ('Donald', 'Trump,'), ('Trump,', 'is'), ('is', '1.9m'), ('1.9m', 'high'), ('high', 'and'), ('and', '78'), ('78', 'years'), ('years', 'old.'), ('old.', 'Forbes'), ('Forbes', 'Magazine'), ('Magazine', 'has'), ('has', 'assessed'), ('assessed', 'his'), ('his', 'wealth,'), ('wealth,', 'currently'), ('currently', 'estimating'), ('estimating', 'it'), ('it', 'at'), ('at', '$5.5'), ('$5.5', 'billion'), ('billion', 'as'), ('as', 'of'), ('of', 'mid-February'), ('mid-February', '2025.')]\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 6 - Create bigrams with pure python.\n",
    "def bigrams(text: str) -> list:\n",
    "    tokens = text.split()\n",
    "    return [(tokens[i], tokens[i+1]) for i in range(len(tokens) - 1)]\n",
    "print(bigrams(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2 point) 7 - Create a language model that predict the next word using bigrams. Please explain in the code how you made the calculations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
