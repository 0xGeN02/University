# Schema: Agents and Environments in Artificial Intelligence

1. Introduction
   - Definition of an agent
   - Components: Sensors, rules, actuators
   - Agent function and agent program

2. Rational Agents
   - Performance measures
   - Factors influencing rationality
   - Rationality vs. omniscience
   - Information gathering for decision-making

3. Task Environments (PEAS Framework)
   - Performance
   - Environment
   - Actuators
   - Sensors

4. Environment Classification (Seven Dimensions)
   1. Observability
      - Fully observable
      - Partially observable
   2. Agents
      - Single-agent
      - Multi-agent (competitive vs. cooperative)
   3. Determinism
      - Deterministic
      - Stochastic
      - Non-deterministic
   4. Episodic vs. Sequential
      - Episodic (independent decision-making)
      - Sequential (long-term planning)
   5. Dynamism
      - Static
      - Dynamic
      - Semi-dynamic
   6. Discrete vs. Continuous
      - Discrete states, actions, and time
      - Continuous states and real-time operations
   7. Known vs. Unknown
      - Known rules and structure
      - Unknown, requiring learning

5. Agent Architectures
   - Simple reflex agents
   - Model-based reflex agents
   - Goal-based agents
   - Utility-based agents

6. State Representations
   - Atomic representation
   - Factorized representation
   - Structured representation

7. Conclusion
   - Importance of understanding agents and environments
   - Future developments in multi-representational intelligence
